//! MongoDBç¼“å­˜ç»•è¿‡æ€§èƒ½å¯¹æ¯”ç¤ºä¾‹
//!
//! æœ¬ç¤ºä¾‹å¯¹æ¯”ä½¿ç”¨ç¼“å­˜å’Œå¼ºåˆ¶è·³è¿‡ç¼“å­˜çš„MongoDBæ•°æ®åº“æ“ä½œæ€§èƒ½å·®å¼‚
//! ä½¿ç”¨ MongoDB æ•°æ®åº“è¿›è¡Œæµ‹è¯•ï¼Œæ”¯æŒ TLSã€è®¤è¯å’Œ ZSTD å‹ç¼©

use rat_logger::{LoggerBuilder, debug, handler::term::TermConfig};
use rat_quickdb::manager::shutdown;
use rat_quickdb::types::*;
use rat_quickdb::*;
use rat_quickdb::{ModelOperations, datetime_field, float_field, integer_field, string_field, uuid_field};
use std::collections::HashMap;
use std::path::PathBuf;
use std::time::{Duration, Instant};
use tokio::time::sleep;

// å®šä¹‰ç¼“å­˜æ•°æ®åº“ç”¨æˆ·æ¨¡å‹
define_model! {
    /// ç”¨æˆ·æ¨¡å‹ï¼ˆç¼“å­˜ç‰ˆæœ¬ï¼‰
    struct CachedUser {
        id: String,
        name: String,
        email: String,
        age: i32,
        created_at: chrono::DateTime<chrono::Utc>,
    }
    collection = "users",
    database = "cached_mongodb",
    fields = {
        id: uuid_field().required().unique(),
        name: string_field(Some(100), Some(1), None).required(),
        email: string_field(Some(255), Some(1), None).required(),
        age: integer_field(Some(0), Some(150)).required(),
        created_at: datetime_field().required(),
    }
    indexes = [
        { fields: ["name"], unique: false, name: "idx_name" },
        { fields: ["age"], unique: false, name: "idx_age" },
        { fields: ["email"], unique: true, name: "idx_email" },
        { fields: ["created_at"], unique: false, name: "idx_created_at" },
    ],
}


/// æ€§èƒ½æµ‹è¯•ç»“æœ
#[derive(Debug, Clone)]
struct PerformanceResult {
    operation: String,
    with_cache: Duration,
    without_cache: Duration,
    improvement_ratio: f64,
    cache_hit_rate: Option<f64>,
}

impl PerformanceResult {
    fn new(operation: String, with_cache: Duration, without_cache: Duration) -> Self {
        let improvement_ratio = if without_cache.as_millis() > 0 {
            without_cache.as_millis() as f64 / with_cache.as_millis() as f64
        } else {
            1.0
        };

        Self {
            operation,
            with_cache,
            without_cache,
            improvement_ratio,
            cache_hit_rate: None,
        }
    }

    fn with_cache_hit_rate(mut self, hit_rate: f64) -> Self {
        self.cache_hit_rate = Some(hit_rate);
        self
    }
}

/// ç¼“å­˜æ€§èƒ½å¯¹æ¯”æµ‹è¯•
struct MongoCacheBypassTest {
    /// æµ‹è¯•ç»“æœ
    results: Vec<PerformanceResult>,
}

impl MongoCacheBypassTest {
    /// åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ
    async fn new() -> QuickDbResult<Self> {
        println!("ğŸš€ åˆå§‹åŒ–MongoDBç¼“å­˜æ€§èƒ½å¯¹æ¯”æµ‹è¯•ç¯å¢ƒ...");

        // åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
        LoggerBuilder::new()
            .add_terminal_with_config(TermConfig::default())
            .init()
            .expect("æ—¥å¿—åˆå§‹åŒ–å¤±è´¥");

        rat_quickdb::init();

        // åˆ›å»ºå¸¦ç¼“å­˜çš„æ•°æ®åº“é…ç½®ï¼ˆL1 + L2ï¼‰
        let cached_config = Self::create_cached_database_config();

        // æ·»åŠ æ•°æ®åº“é…ç½®
        add_database(cached_config).await?;

        // è®¾ç½®é»˜è®¤æ•°æ®åº“åˆ«åä¸ºç¼“å­˜æ•°æ®åº“
        set_default_alias("cached_mongodb").await?;

        println!("âœ… æµ‹è¯•ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ");

        Ok(Self {
            results: Vec::new(),
        })
    }

    /// åˆ›å»ºå¸¦ç¼“å­˜çš„MongoDBæ•°æ®åº“é…ç½®ï¼ˆL1 + L2ï¼‰
    fn create_cached_database_config() -> DatabaseConfig {
        // TLSé…ç½®
        let tls_config = TlsConfig {
            enabled: true,
            ca_cert_path: None,
            client_cert_path: None,
            client_key_path: None,
            verify_server_cert: false,
            verify_hostname: false,
            min_tls_version: Some("1.2".to_string()),
            cipher_suites: None,
        };

        // ZSTDå‹ç¼©é…ç½®
        let zstd_config = ZstdConfig {
            enabled: true,
            compression_level: Some(3),
            compression_threshold: Some(1024),
        };

        // L1ç¼“å­˜é…ç½®ï¼ˆå†…å­˜ç¼“å­˜ï¼‰
        let l1_config = L1CacheConfig {
            max_capacity: 1000, // æœ€å¤§1000ä¸ªæ¡ç›®
            max_memory_mb: 64,  // 64MBå†…å­˜é™åˆ¶
            enable_stats: true, // å¯ç”¨ç»Ÿè®¡
        };

        // L2ç¼“å­˜é…ç½®ï¼ˆç£ç›˜ç¼“å­˜ï¼‰
        let l2_config = Some(
            L2CacheConfig::new("./cache/mongodb_cache_test".to_string())
                .with_max_disk_mb(512) // 512MBç£ç›˜ç¼“å­˜
                .with_compression_level(3) // ZSTDå‹ç¼©çº§åˆ«
                .enable_wal(true) // å¯ç”¨WALæ¨¡å¼
                .clear_on_startup(true), // å¯åŠ¨æ—¶æ¸…ç†ç¼“å­˜
        );

        // TTLé…ç½®
        let ttl_config = TtlConfig {
            default_ttl_secs: 1800,   // é»˜è®¤30åˆ†é’Ÿ
            max_ttl_secs: 7200,       // æœ€å¤§2å°æ—¶
            check_interval_secs: 120, // æ£€æŸ¥é—´éš”2åˆ†é’Ÿ
        };

        // å‹ç¼©é…ç½®
        let compression_config = CompressionConfig {
            enabled: true,
            algorithm: CompressionAlgorithm::Zstd,
            threshold_bytes: 1024, // 1KBä»¥ä¸Šæ‰å‹ç¼©
        };

        // å®Œæ•´çš„ç¼“å­˜é…ç½®
        let cache_config = CacheConfig {
            enabled: true,
            strategy: CacheStrategy::Lru,
            l1_config,
            l2_config,
            ttl_config,
            compression_config,
            version: "v1".to_string(),
        };

        // æ„å»ºMongoDBè¿æ¥é…ç½®
        let builder = MongoDbConnectionBuilder::new(
            "db0.0ldm0s.net".to_string(),
            27017,
            "testdb".to_string(),
        )
        .with_auth("testdb", "testdb123456")
        .with_auth_source("testdb")
        .with_direct_connection(true)
        .with_tls_config(tls_config)
        .with_zstd_config(zstd_config);

        DatabaseConfig {
            db_type: DatabaseType::MongoDB,
            connection: builder.build(),
            pool: PoolConfig {
                min_connections: 1,
                max_connections: 1,
                connection_timeout: 10000, // 10ç§’
                idle_timeout: 600,         // 10åˆ†é’Ÿ
                max_lifetime: 1800,        // 30åˆ†é’Ÿ
                max_retries: 3,
                retry_interval_ms: 1000,
                keepalive_interval_sec: 60,
                health_check_timeout_sec: 10,
            },
            alias: "cached_mongodb".to_string(),
            cache: Some(cache_config),
            id_strategy: IdStrategy::Uuid,
        }
    }

  
    /// è¿è¡Œæ‰€æœ‰æ€§èƒ½æµ‹è¯•
    async fn run_all_tests(&mut self) -> QuickDbResult<()> {
        // 1. è®¾ç½®æµ‹è¯•æ•°æ®
        self.setup_test_data().await?;

        // 2. é¢„çƒ­ç¼“å­˜
        self.warmup_cache().await?;

        // 3. è¿è¡Œå„é¡¹æµ‹è¯•
        self.test_query_operations().await?;
        self.test_repeated_queries().await?;
        self.test_batch_queries().await?;
        self.test_update_operations().await?;

        Ok(())
    }

    /// è®¾ç½®æµ‹è¯•æ•°æ®
    async fn setup_test_data(&mut self) -> QuickDbResult<()> {
        println!("\nğŸ”§ è®¾ç½®MongoDBæµ‹è¯•æ•°æ®...");

        // æ¸…ç†å¯èƒ½å­˜åœ¨çš„æµ‹è¯•æ•°æ®
        println!("  æ¸…ç†å¯èƒ½å­˜åœ¨çš„æµ‹è¯•æ•°æ®...");
        let _ = drop_table("cached_mongodb", "users").await;

        // åˆ›å»ºæµ‹è¯•ç”¨æˆ·æ•°æ®
        let users = vec![
            self.create_cached_user("user1", "å¼ ä¸‰", "zhangsan@example.com", 25),
            self.create_cached_user("user2", "æå››", "lisi@example.com", 30),
            self.create_cached_user("user3", "ç‹äº”", "wangwu@example.com", 28),
            self.create_cached_user("user4", "èµµå…­", "zhaoliu@example.com", 35),
            self.create_cached_user("user5", "é’±ä¸ƒ", "qianqi@example.com", 22),
        ];

        // æ‰¹é‡ç”¨æˆ·æ•°æ®
        let batch_users: Vec<CachedUser> = (6..=25)
            .map(|i| {
                self.create_cached_user(
                    &format!("batch_user_{}", i),
                    &format!("æ‰¹é‡ç”¨æˆ·{}", i),
                    &format!("batch{}@example.com", i),
                    20 + (i % 30),
                )
            })
            .collect();

        // åˆ›å»ºæµ‹è¯•æ•°æ®åˆ°æ•°æ®åº“
        println!("  åˆ›å»ºæµ‹è¯•æ•°æ®åˆ°æ•°æ®åº“...");
        set_default_alias("cached_mongodb").await?;
        for user in users.iter().chain(batch_users.iter()) {
            let mut user_clone = user.clone();
            user_clone.save().await?;
        }

        println!(
            "  âœ… åˆ›å»ºäº† {} æ¡æµ‹è¯•è®°å½•",
            users.len() + batch_users.len()
        );
        Ok(())
    }

    /// åˆ›å»ºç¼“å­˜ç”¨æˆ·æ•°æ®
    fn create_cached_user(&self, _id: &str, name: &str, email: &str, age: i32) -> CachedUser {
        CachedUser {
            id: String::new(), // ä½¿ç”¨ç©ºå­—ç¬¦ä¸²è®©ç³»ç»Ÿè‡ªåŠ¨ç”ŸæˆUUID
            name: name.to_string(),
            email: email.to_string(),
            age,
            created_at: chrono::Utc::now(),
        }
    }

    /// ç¼“å­˜é¢„çƒ­
    async fn warmup_cache(&mut self) -> QuickDbResult<()> {
        println!("\nğŸ”¥ ç¼“å­˜é¢„çƒ­...");

        // è®¾ç½®ä½¿ç”¨ç¼“å­˜æ•°æ®åº“
        set_default_alias("cached_mongodb").await?;

        // æ‰§è¡Œä¸€äº›æŸ¥è¯¢æ“ä½œæ¥é¢„çƒ­ç¼“å­˜
        let conditions = vec![QueryCondition {
            field: "age".to_string(),
            operator: QueryOperator::Gt,
            value: DataValue::Int(20),
        }];

        // é¢„çƒ­æŸ¥è¯¢
        let _result = ModelManager::<CachedUser>::find(conditions, None).await?;

        // æŒ‰IDæŸ¥è¯¢é¢„çƒ­
        let users = ModelManager::<CachedUser>::find(vec![], None).await?;
        if let Some(first_user) = users.first() {
            let _result = ModelManager::<CachedUser>::find_by_id(&first_user.id).await?;
        }

        println!("  âœ… ç¼“å­˜é¢„çƒ­å®Œæˆ");
        Ok(())
    }

    /// æµ‹è¯•æŸ¥è¯¢æ“ä½œæ€§èƒ½
    async fn test_query_operations(&mut self) -> QuickDbResult<()> {
        println!("\nğŸ” æµ‹è¯•MongoDBæŸ¥è¯¢æ“ä½œæ€§èƒ½...");

        let conditions = vec![QueryCondition {
            field: "name".to_string(),
            operator: QueryOperator::Eq,
            value: DataValue::String("å¼ ä¸‰".to_string()),
        }];

        // ç¬¬ä¸€æ¬¡æŸ¥è¯¢ï¼ˆå†·å¯åŠ¨ï¼Œä»æ•°æ®åº“è¯»å–ï¼‰
        set_default_alias("cached_mongodb").await?;
        let start = Instant::now();
        let _result1 = ModelManager::<CachedUser>::find(conditions.clone(), None).await?;
        let first_query_duration = start.elapsed();

        // ç¬¬äºŒæ¬¡æŸ¥è¯¢ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
        let start = Instant::now();
        let _result2 = ModelManager::<CachedUser>::find(conditions, None).await?;
        let cached_duration = start.elapsed();

        let result = PerformanceResult::new(
            "å•æ¬¡æŸ¥è¯¢æ“ä½œ".to_string(),
            cached_duration,
            first_query_duration,
        );

        println!("  âœ… é¦–æ¬¡æŸ¥è¯¢ï¼ˆæ•°æ®åº“ï¼‰: {:?}", first_query_duration);
        println!("  âœ… ç¼“å­˜æŸ¥è¯¢: {:?}", cached_duration);
        println!("  ğŸ“ˆ æ€§èƒ½æå‡: {:.2}x", result.improvement_ratio);

        self.results.push(result);
        Ok(())
    }

    /// æµ‹è¯•é‡å¤æŸ¥è¯¢ï¼ˆbypass_cache vs ç¼“å­˜ï¼‰
    async fn test_repeated_queries(&mut self) -> QuickDbResult<()> {
        println!("\nğŸ”„ æµ‹è¯•MongoDBé‡å¤æŸ¥è¯¢æ€§èƒ½ï¼ˆbypass_cache vs ç¼“å­˜ï¼‰...");

        let conditions = vec![QueryCondition {
            field: "age".to_string(),
            operator: QueryOperator::Gt,
            value: DataValue::Int(20),
        }];

        let query_count = 10;

        // æµ‹é‡å¼ºåˆ¶è·³è¿‡ç¼“å­˜çš„æŸ¥è¯¢æ—¶é—´
        set_default_alias("cached_mongodb").await?;
        let start = Instant::now();
        for _ in 0..query_count {
            let _result = ModelManager::<CachedUser>::find_with_cache_control(conditions.clone(), None, true).await?;
            // çŸ­æš‚å»¶è¿Ÿä»¥æ¨¡æ‹ŸçœŸå®åœºæ™¯
            sleep(Duration::from_millis(5)).await;
        }
        let non_cached_duration = start.elapsed();

        // é¦–æ¬¡æŸ¥è¯¢ï¼ˆå»ºç«‹ç¼“å­˜ï¼‰
        set_default_alias("cached_mongodb").await?;
        let _result = ModelManager::<CachedUser>::find(conditions.clone(), None).await?;

        // æµ‹è¯•é‡å¤æŸ¥è¯¢ï¼ˆåº”è¯¥ä»ç¼“å­˜è¯»å–ï¼‰
        let start = Instant::now();
        for _ in 0..query_count {
            let _result = ModelManager::<CachedUser>::find(conditions.clone(), None).await?;
            // çŸ­æš‚å»¶è¿Ÿä»¥æ¨¡æ‹ŸçœŸå®åœºæ™¯
            sleep(Duration::from_millis(5)).await;
        }
        let cached_duration = start.elapsed();

        // è®¡ç®—å¹³å‡å•æ¬¡æŸ¥è¯¢æ—¶é—´
        let avg_cached_time = cached_duration / query_count;
        let avg_non_cached_time = non_cached_duration / query_count;

        let result = PerformanceResult::new(
            format!("é‡å¤æŸ¥è¯¢ ({}æ¬¡)", query_count),
            avg_cached_time,
            avg_non_cached_time,
        )
        .with_cache_hit_rate(95.0); // å‡è®¾95%çš„ç¼“å­˜å‘½ä¸­ç‡

        println!("  âœ… å¼ºåˆ¶è·³è¿‡ç¼“å­˜æ€»è€—æ—¶: {:?}", non_cached_duration);
        println!("  âœ… ä½¿ç”¨ç¼“å­˜æ€»è€—æ—¶: {:?}", cached_duration);
        println!("  âœ… å¼ºåˆ¶è·³è¿‡ç¼“å­˜å¹³å‡æŸ¥è¯¢: {:?}", avg_non_cached_time);
        println!("  âœ… ä½¿ç”¨ç¼“å­˜å¹³å‡æŸ¥è¯¢: {:?}", avg_cached_time);
        println!("  ğŸ“ˆ æ€§èƒ½æå‡: {:.2}x", result.improvement_ratio);
        println!(
            "  ğŸ¯ ç¼“å­˜å‘½ä¸­ç‡: {:.1}%",
            result.cache_hit_rate.unwrap_or(0.0)
        );

        self.results.push(result);
        Ok(())
    }

    /// æµ‹è¯•æ‰¹é‡æŸ¥è¯¢æ€§èƒ½
    async fn test_batch_queries(&mut self) -> QuickDbResult<()> {
        println!("\nğŸ“¦ æµ‹è¯•MongoDBæ‰¹é‡æŸ¥è¯¢æ€§èƒ½...");

        let user_ids = vec!["user1", "user2", "user3", "user4", "user5"];

        // é¦–æ¬¡æ‰¹é‡æŸ¥è¯¢ï¼ˆå»ºç«‹ç¼“å­˜ï¼‰
        set_default_alias("cached_mongodb").await?;
        let start = Instant::now();
        for user_id in &user_ids {
            let _result = ModelManager::<CachedUser>::find_by_id(user_id).await?;
        }
        let first_batch_duration = start.elapsed();

        // ç¬¬äºŒæ¬¡æ‰¹é‡æŸ¥è¯¢ï¼ˆç¼“å­˜å‘½ä¸­ï¼‰
        let start = Instant::now();
        for user_id in &user_ids {
            let _result = ModelManager::<CachedUser>::find_by_id(user_id).await?;
        }
        let cached_duration = start.elapsed();

        let result = PerformanceResult::new(
            format!("æ‰¹é‡IDæŸ¥è¯¢ ({}æ¡è®°å½•)", user_ids.len()),
            cached_duration,
            first_batch_duration,
        );

        println!("  âœ… é¦–æ¬¡æ‰¹é‡æŸ¥è¯¢: {:?}", first_batch_duration);
        println!("  âœ… ç¼“å­˜æ‰¹é‡æŸ¥è¯¢: {:?}", cached_duration);
        println!("  ğŸ“ˆ æ€§èƒ½æå‡: {:.2}x", result.improvement_ratio);

        self.results.push(result);
        Ok(())
    }

    /// æµ‹è¯•æ›´æ–°æ“ä½œæ€§èƒ½
    async fn test_update_operations(&mut self) -> QuickDbResult<()> {
        println!("\nâœï¸ æµ‹è¯•MongoDBæ›´æ–°æ“ä½œæ€§èƒ½...");

        let conditions = vec![QueryCondition {
            field: "name".to_string(),
            operator: QueryOperator::Eq,
            value: DataValue::String("å¼ ä¸‰".to_string()),
        }];

        // æŸ¥æ‰¾è¦æ›´æ–°çš„ç”¨æˆ·
        set_default_alias("cached_mongodb").await?;
        let users = ModelManager::<CachedUser>::find(conditions.clone(), None).await?;
        if let Some(user) = users.first() {
            // ç¬¬ä¸€æ¬¡æ›´æ–°æ“ä½œ
            let start = Instant::now();
            let mut user_clone = user.clone();
            user_clone.age = 26;
            user_clone.email = "zhangsan_new@example.com".to_string();
            let mut updates = HashMap::new();
            updates.insert("age".to_string(), DataValue::Int(26));
            updates.insert(
                "email".to_string(),
                DataValue::String("zhangsan_new@example.com".to_string()),
            );
            let _update_result = user_clone.update(updates).await?;
            let first_update_duration = start.elapsed();

            // æ¢å¤æ•°æ®ä»¥ä¾¿ç¬¬äºŒæ¬¡æ›´æ–°
            let mut user_restore = user_clone.clone();
            user_restore.age = 25;
            user_restore.email = "zhangsan@example.com".to_string();
            let mut restore_updates = HashMap::new();
            restore_updates.insert("age".to_string(), DataValue::Int(25));
            restore_updates.insert(
                "email".to_string(),
                DataValue::String("zhangsan@example.com".to_string()),
            );
            let _restore_result = user_restore.update(restore_updates).await?;

            // ç¬¬äºŒæ¬¡æ›´æ–°æ“ä½œï¼ˆå¯èƒ½æœ‰ç¼“å­˜ä¼˜åŒ–ï¼‰
            let start = Instant::now();
            let mut user_update2 = user.clone();
            user_update2.age = 26;
            user_update2.email = "zhangsan_new@example.com".to_string();
            let mut updates2 = HashMap::new();
            updates2.insert("age".to_string(), DataValue::Int(26));
            updates2.insert(
                "email".to_string(),
                DataValue::String("zhangsan_new@example.com".to_string()),
            );
            let _update_result2 = user_update2.update(updates2).await?;
            let second_update_duration = start.elapsed();

            let result = PerformanceResult::new(
                "æ›´æ–°æ“ä½œ".to_string(),
                second_update_duration,
                first_update_duration,
            );

            println!("  âœ… é¦–æ¬¡æ›´æ–°: {:?}", first_update_duration);
            println!("  âœ… ç¬¬äºŒæ¬¡æ›´æ–°: {:?}", second_update_duration);
            println!("  ğŸ“ˆ æ€§èƒ½å˜åŒ–: {:.2}x", result.improvement_ratio);

            self.results.push(result);
        } else {
            println!("  âš ï¸ æœªæ‰¾åˆ°æµ‹è¯•ç”¨æˆ·ï¼Œè·³è¿‡æ›´æ–°æµ‹è¯•");
        }

        Ok(())
    }

    /// æ˜¾ç¤ºæµ‹è¯•ç»“æœæ±‡æ€»
    fn display_results(&self) {
        println!("\nğŸ“Š ==================== MongoDBç¼“å­˜ç»•è¿‡æµ‹è¯•ç»“æœæ±‡æ€» ====================");
        println!("è¿æ¥é…ç½®: db0.0ldm0s.net:27017 (TLS + ZSTD + directConnection)");
        println!("æ•°æ®åº“: testdb, è®¤è¯æº: testdb");
        println!(
            "{:<25} {:<15} {:<20} {:<10} {:<10}",
            "æ“ä½œç±»å‹", "ä½¿ç”¨ç¼“å­˜(ms)", "å¼ºåˆ¶è·³è¿‡ç¼“å­˜(ms)", "æå‡å€æ•°", "ç¼“å­˜å‘½ä¸­ç‡"
        );
        println!("{}", "-".repeat(80));

        let mut total_improvement = 0.0;
        let mut count = 0;

        for result in &self.results {
            let cache_hit_str = if let Some(hit_rate) = result.cache_hit_rate {
                format!("{:.1}%", hit_rate)
            } else {
                "N/A".to_string()
            };

            println!(
                "{:<25} {:<15.3} {:<20.3} {:<10.2} {:<10}",
                result.operation,
                result.with_cache.as_millis(),
                result.without_cache.as_millis(),
                result.improvement_ratio,
                cache_hit_str
            );

            total_improvement += result.improvement_ratio;
            count += 1;
        }

        println!("{}", "-".repeat(80));

        if count > 0 {
            let avg_improvement = total_improvement / count as f64;
            println!("ğŸ“ˆ å¹³å‡æ€§èƒ½æå‡: {:.2}x", avg_improvement);

            if avg_improvement > 1.5 {
                println!("ğŸ‰ ç¼“å­˜æ˜¾è‘—æå‡äº†MongoDBæ•°æ®åº“æ“ä½œæ€§èƒ½ï¼");
            } else if avg_improvement > 1.1 {
                println!("âœ… ç¼“å­˜é€‚åº¦æå‡äº†MongoDBæ•°æ®åº“æ“ä½œæ€§èƒ½ã€‚");
            } else {
                println!("âš ï¸ ç¼“å­˜å¯¹æ€§èƒ½æå‡æœ‰é™ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´ç¼“å­˜ç­–ç•¥ã€‚");
            }
        }

        println!("\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:");
        println!("   â€¢ å¯¹äºé¢‘ç¹æŸ¥è¯¢çš„æ•°æ®ï¼Œç¼“å­˜èƒ½æ˜¾è‘—æå‡æ€§èƒ½");
        println!("   â€¢ é‡å¤æŸ¥è¯¢åœºæ™¯ä¸‹ï¼Œç¼“å­˜å‘½ä¸­ç‡è¶Šé«˜ï¼Œæ€§èƒ½æå‡è¶Šæ˜æ˜¾");
        println!("   â€¢ å†™æ“ä½œï¼ˆåˆ›å»ºã€æ›´æ–°ï¼‰çš„æ€§èƒ½æå‡ç›¸å¯¹æœ‰é™");
        println!("   â€¢ å¯æ ¹æ®å®é™…ä¸šåŠ¡åœºæ™¯è°ƒæ•´ç¼“å­˜ TTL å’Œå®¹é‡é…ç½®");

        println!("\nğŸ”§ ç¼“å­˜é…ç½®ä¿¡æ¯:");
        println!("   â€¢ ç¼“å­˜ç­–ç•¥: LRU");
        println!("   â€¢ L1 ç¼“å­˜å®¹é‡: 1000 æ¡è®°å½•");
        println!("   â€¢ L1 ç¼“å­˜å†…å­˜é™åˆ¶: 64 MB");
        println!("   â€¢ L2 ç¼“å­˜å®¹é‡: 512 MB ç£ç›˜ç©ºé—´");
        println!("   â€¢ L2 ç¼“å­˜ç›®å½•: ./cache/mongodb_cache_test");
        println!("   â€¢ é»˜è®¤ TTL: 30 åˆ†é’Ÿ");
        println!("   â€¢ æœ€å¤§ TTL: 2 å°æ—¶");
        println!("   â€¢ å‹ç¼©ç®—æ³•: ZSTD");
        println!("   â€¢ MongoDBè¿æ¥: TLS + ZSTDå‹ç¼© + ç›´è¿æ¨¡å¼");
    }
}

/// åˆ›å»ºç¼“å­˜ç›®å½•
async fn setup_cache_directory() -> QuickDbResult<()> {
    let cache_dir = "./cache/mongodb_cache_test";
    if let Err(e) = tokio::fs::create_dir_all(cache_dir).await {
        println!("âš ï¸ åˆ›å»ºç¼“å­˜ç›®å½•å¤±è´¥: {}", e);
        // ä¸è¿”å›é”™è¯¯ï¼Œç»§ç»­æ‰§è¡Œ
    } else {
        println!("âœ… ç¼“å­˜ç›®å½•åˆ›å»ºæˆåŠŸ: {}", cache_dir);
    }
    Ok(())
}

/// æ¸…ç†æµ‹è¯•æ–‡ä»¶
async fn cleanup_test_files() {
    // æ¸…ç†ç¼“å­˜ç›®å½•
    let cache_dir = "./cache/mongodb_cache_test";
    if std::path::Path::new(cache_dir).exists() {
        if let Err(e) = tokio::fs::remove_dir_all(cache_dir).await {
            println!("âš ï¸ æ¸…ç†ç¼“å­˜ç›®å½• {} å¤±è´¥: {}", cache_dir, e);
        } else {
            println!("ğŸ—‘ï¸ å·²æ¸…ç†ç¼“å­˜ç›®å½•: {}", cache_dir);
        }
    }

    println!("ğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶å®Œæˆ");
}

#[tokio::main]
async fn main() -> QuickDbResult<()> {
    println!("ğŸš€ RatQuickDB MongoDBç¼“å­˜ç»•è¿‡æµ‹è¯•");
    println!("=====================================\n");

    // æ¸…ç†ä¹‹å‰çš„æµ‹è¯•æ–‡ä»¶
    cleanup_test_files().await;

    // åˆ›å»ºç¼“å­˜ç›®å½•
    setup_cache_directory().await?;

    // åˆ›å»ºå¹¶è¿è¡Œæµ‹è¯•
    let mut test = MongoCacheBypassTest::new().await?;
    test.run_all_tests().await?;

    // æ˜¾ç¤ºæµ‹è¯•ç»“æœ
    test.display_results();

    // æ¸…ç†æµ‹è¯•æ–‡ä»¶
    cleanup_test_files().await;

    // å…³é—­è¿æ¥æ± 
    shutdown().await?;

    println!("\nğŸ¯ æµ‹è¯•å®Œæˆï¼æ„Ÿè°¢ä½¿ç”¨ RatQuickDB MongoDBç¼“å­˜ç»•è¿‡åŠŸèƒ½ã€‚");

    Ok(())
}
